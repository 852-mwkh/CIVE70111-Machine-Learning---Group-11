{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a07f3d",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/06/Imperial_College_London_new_logo.png\" alt=\"Imperial Logo\" width=\"400\">\n",
    "\n",
    "### **Course:** CIVE70111 Machine Learning\n",
    "### Task 4 PV Plant Modelling and Machine Learning Pipeline\n",
    "\n",
    "**Project:** Clssification of operation conditions\n",
    "\n",
    "**Date:** 09/12/2025  \n",
    "\n",
    "<p align=\"right\">\n",
    "Created by: Michael Wong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed56e38",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. **Project Overview**\n",
    "2. **Workflow Summary**\n",
    "3. **Imports & Paths**\n",
    "4. **Helper Functions**\n",
    "5. **Machine Learning Helpers**\n",
    "6. **End-to-End Classification Pipeline**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb11de",
   "metadata": {},
   "source": [
    "# 1. Project Overview\n",
    "\n",
    "This project focuses on detecting **suboptimal inverter operating conditions** in two solar power plants.\n",
    "Each plant contains multiple inverters and weather sensors recording AC/DC power, yield, irradiance,\n",
    "and temperature. The dataset contains numerous real-world issues including missing values, inconsistent\n",
    "measurements, noisy power output at night, and non-monotonic yield counters.\n",
    "\n",
    "The goal is to develop a **robust and interpretable machine learning model** that:\n",
    "\n",
    "- Predicts inverter state as **Optimal (0)** or **Suboptimal (1)**\n",
    "- Uses strict **time-based splitting** to avoid data leakage\n",
    "- Is evaluated using F1-score with emphasis on Suboptimal detection\n",
    "- Incorporates **data cleaning, outlier removal, feature engineering**\n",
    "- Provides **engineering interpretability** using ALE and Drop-Column Importance\n",
    "\n",
    "The final system integrates preprocessing, model training, evaluation,\n",
    "and interpretability into a fully automated pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e23e92",
   "metadata": {},
   "source": [
    "# 2. Workflow Summary\n",
    "\n",
    "The overall workflow is divided into six major stages:\n",
    "\n",
    "1. **Imports & Paths**\n",
    "   - Load required Python libraries\n",
    "   - Define file locations for Plant 1 and Plant 2 datasets\n",
    "\n",
    "2. **Helper Functions**\n",
    "   - Weather cleaning\n",
    "   - AC/DC cleaning\n",
    "   - Daily and total yield correction\n",
    "   - Outlier removal\n",
    "   - Merging inverter and weather data\n",
    "\n",
    "3. **Machine Learning Helper Functions**\n",
    "   - Label construction\n",
    "   - Feature engineering (AC/IRRA, DC/IRRA)\n",
    "   - Train/validation/test splitting\n",
    "   - Threshold optimisation for Suboptimal F1\n",
    "   - ALE plotting and drop-column importance\n",
    "\n",
    "4. **End-to-End Classification Pipeline**\n",
    "   - Assemble datasets\n",
    "   - Clean and engineer features\n",
    "   - Split chronologically\n",
    "   - Train Logistic Regression and Linear SVM (scaled/unscaled)\n",
    "   - Generate evaluation metrics\n",
    "   - Produce ALE interpretability plots\n",
    "   - Compute drop-column feature importance\n",
    "\n",
    "5. **Experiments**\n",
    "   - With vs. without outlier removal\n",
    "   - Before vs. after feature selection\n",
    "   - Plant 1 vs. Plant 2 comparison\n",
    "\n",
    "6. **Results Interpretation**\n",
    "   - Performance comparison across plants and models\n",
    "   - Importance of each input feature\n",
    "   - Impact of outlier removal\n",
    "   - Engineering insights into inverter performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9397f9e2",
   "metadata": {},
   "source": [
    "# 3. Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f5d85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Disable all plot display\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, classification_report, confusion_matrix,\n",
    "    f1_score, average_precision_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from PyALE import ale\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "logging.getLogger(\"PyALE\").setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75031845",
   "metadata": {},
   "source": [
    "# 4. Helper Functions \n",
    "### Weather, AC/DC, Yield, Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ccfd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def regression_outlier_detection_graph(df, x_col=\"IRRADIATION_CLEAN\",\n",
    "                                       y_col=\"AC_CLEAN\", z_thresh=3, plot=True):\n",
    "    df = df.copy()\n",
    "    mask_valid = df[[x_col, y_col]].notna().all(axis=1)\n",
    "    if mask_valid.sum() < 10:\n",
    "        return df\n",
    "\n",
    "    X = df.loc[mask_valid, [x_col]].values\n",
    "    y = df.loc[mask_valid, y_col].values\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    residuals = y - y_pred\n",
    "    z = (residuals - residuals.mean()) / residuals.std(ddof=0)\n",
    "    outlier_mask = np.abs(z) > z_thresh\n",
    "\n",
    "    df_valid = df.loc[mask_valid].copy()\n",
    "    df_valid[\"outlier_reg\"] = outlier_mask\n",
    "\n",
    "    df_clean = df_valid.loc[~df_valid[\"outlier_reg\"]].drop(columns=[\"outlier_reg\"])\n",
    "    df_rest = df.loc[~mask_valid]\n",
    "    df_result = pd.concat([df_clean, df_rest], axis=0).sort_index()\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2c35e",
   "metadata": {},
   "source": [
    "### Weather Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3f8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df_weather_raw):\n",
    "    \"\"\"\n",
    "    Create IRRADIATION_CLEAN using simple 6:00–18:30 day/night rule,\n",
    "    drop SOURCE_KEY, and set DATE_TIME as index.\n",
    "    \"\"\"\n",
    "    dfw = df_weather_raw.copy()\n",
    "    dfw[\"DATE_TIME\"] = pd.to_datetime(dfw[\"DATE_TIME\"])\n",
    "\n",
    "    day_start = dt.time(6, 0)\n",
    "    day_end   = dt.time(18, 30)\n",
    "    dfw[\"expected_day\"] = dfw[\"DATE_TIME\"].dt.time.between(day_start, day_end)\n",
    "\n",
    "    dfw[\"IRRADIATION_CLEAN\"] = dfw[\"IRRADIATION\"].copy()\n",
    "    dfw.loc[(~dfw[\"expected_day\"]) & (dfw[\"IRRADIATION_CLEAN\"] > 0), \"IRRADIATION_CLEAN\"] = 0\n",
    "\n",
    "    dfw.set_index(\"DATE_TIME\", inplace=True)\n",
    "    if \"SOURCE_KEY\" in dfw.columns:\n",
    "        dfw = dfw.drop(columns=[\"SOURCE_KEY\"])\n",
    "\n",
    "    return dfw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1dece",
   "metadata": {},
   "source": [
    "### Aggregating Generation Data by Inverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6c88dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_inverters(df_gen_clean):\n",
    "    \"\"\"\n",
    "    Aggregate generation data per inverter and time, and count Optimal/Suboptimal.\n",
    "    Returns dict: {source_key: aggregated_df}\n",
    "    \"\"\"\n",
    "    agg_dict = {}\n",
    "    grouped = df_gen_clean.groupby(\"SOURCE_KEY\")\n",
    "    for sk, g in grouped:\n",
    "        agg_df = g.groupby(\"DATE_TIME\").agg(\n",
    "            SOURCE_KEY=(\"SOURCE_KEY\", \"first\"),\n",
    "            DC_POWER=(\"DC_POWER\", \"first\"),\n",
    "            AC_POWER=(\"AC_POWER\", \"first\"),\n",
    "            DAILY_YIELD=(\"DAILY_YIELD\", \"first\"),\n",
    "            TOTAL_YIELD=(\"TOTAL_YIELD\", \"first\"),\n",
    "            NUM_OPT=(\"Operating_Condition\", lambda x: (x == \"Optimal\").sum()),\n",
    "            NUM_SUBOPT=(\"Operating_Condition\", lambda x: (x == \"Suboptimal\").sum())\n",
    "        ).reset_index()\n",
    "        agg_dict[sk] = agg_df\n",
    "    return agg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522da950",
   "metadata": {},
   "source": [
    "### Merge Inverter + Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61d6d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_inverter_weather(agg_inv_dict, df_weather_clean):\n",
    "    \"\"\"\n",
    "    Inner-join each inverter df with weather df on matching DATE_TIME index.\n",
    "    Returns dict: {source_key: joined_df}\n",
    "    \"\"\"\n",
    "    joined = {}\n",
    "    for sk, inv_df in agg_inv_dict.items():\n",
    "        d = inv_df.copy()\n",
    "        d[\"DATE_TIME\"] = pd.to_datetime(d[\"DATE_TIME\"])\n",
    "        d.set_index(\"DATE_TIME\", inplace=True)\n",
    "        join_df = d.join(df_weather_clean, how=\"inner\")\n",
    "        joined[sk] = join_df\n",
    "    return joined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859158e",
   "metadata": {},
   "source": [
    "### Clean AC/DC Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29447233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ac_dc_dict(wea_inv_dict):\n",
    "    \"\"\"\n",
    "    Clean AC_POWER and DC_POWER into AC_CLEAN/DC_CLEAN based on IRRADIATION_CLEAN.\n",
    "    Returns dict on the same keys.\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    for sk, df_join in wea_inv_dict.items():\n",
    "        d = df_join.copy()\n",
    "        d[\"AC_CLEAN\"] = d[\"AC_POWER\"].copy()\n",
    "        d[\"DC_CLEAN\"] = d[\"DC_POWER\"].copy()\n",
    "\n",
    "        night_mask = d[\"IRRADIATION_CLEAN\"] == 0\n",
    "        d.loc[night_mask & (d[\"AC_CLEAN\"] > 0), \"AC_CLEAN\"] = 0\n",
    "        d.loc[night_mask & (d[\"DC_CLEAN\"] > 0), \"DC_CLEAN\"] = 0\n",
    "\n",
    "        day_mask = d[\"IRRADIATION_CLEAN\"] > 0\n",
    "        d.loc[day_mask & (d[\"AC_CLEAN\"] == 0), \"AC_CLEAN\"] = float(\"nan\")\n",
    "        d.loc[day_mask & (d[\"DC_CLEAN\"] == 0), \"DC_CLEAN\"] = float(\"nan\")\n",
    "\n",
    "        d[\"AC_CLEAN\"] = d[\"AC_CLEAN\"].interpolate(method=\"linear\")\n",
    "        d[\"DC_CLEAN\"] = d[\"DC_CLEAN\"].interpolate(method=\"linear\")\n",
    "\n",
    "        d[\"AC_CLEAN\"] = d[\"AC_CLEAN\"].fillna(0)\n",
    "        d[\"DC_CLEAN\"] = d[\"DC_CLEAN\"].fillna(0)\n",
    "\n",
    "        cleaned[sk] = d\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c407b25",
   "metadata": {},
   "source": [
    "### Clean DAILY_YIELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1b4273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_daily_yield_dict(acdc_dict):\n",
    "    \"\"\"\n",
    "    Enforce DAILY_YIELD_CLEAN:\n",
    "      - 0 at night\n",
    "      - monotonic increasing during daytime\n",
    "      - flat after sunset\n",
    "    Returns dict with DAILY_YIELD_CLEAN added.\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    for sk, df_in in acdc_dict.items():\n",
    "        d = df_in.copy()\n",
    "        d.index = pd.to_datetime(d.index)\n",
    "        d[\"DAILY_YIELD_CLEAN\"] = d[\"DAILY_YIELD\"].copy()\n",
    "\n",
    "        dates = np.unique(d.index.date)\n",
    "        for day in dates:\n",
    "            mask_day_full = d.index.date == day\n",
    "            df_day = d.loc[mask_day_full]\n",
    "\n",
    "            irr_pos = df_day[\"IRRADIATION_CLEAN\"] > 0\n",
    "            if not irr_pos.any():\n",
    "                d.loc[mask_day_full, \"DAILY_YIELD_CLEAN\"] = 0.0\n",
    "                continue\n",
    "\n",
    "            day_start_idx = df_day[irr_pos].index[0]\n",
    "            day_end_idx   = df_day[irr_pos].index[-1]\n",
    "\n",
    "            night_mask   = mask_day_full & (d.index < day_start_idx)\n",
    "            day_mask     = mask_day_full & (d.index >= day_start_idx) & (d.index <= day_end_idx)\n",
    "            evening_mask = mask_day_full & (d.index > day_end_idx)\n",
    "\n",
    "            d.loc[night_mask, \"DAILY_YIELD_CLEAN\"] = 0.0\n",
    "            val_end = d.at[day_end_idx, \"DAILY_YIELD\"]\n",
    "            d.loc[evening_mask, \"DAILY_YIELD_CLEAN\"] = val_end\n",
    "\n",
    "            day_idx = d.loc[day_mask].index\n",
    "            if len(day_idx) == 0:\n",
    "                continue\n",
    "\n",
    "            raw_vals = d.loc[day_idx, \"DAILY_YIELD_CLEAN\"].values.astype(float)\n",
    "            invalid = np.zeros(len(raw_vals), dtype=bool)\n",
    "\n",
    "            invalid |= raw_vals <= 0\n",
    "            if len(raw_vals) > 1:\n",
    "                drops = np.diff(raw_vals) < 0\n",
    "                invalid[1:][drops] = True\n",
    "\n",
    "            d.loc[day_idx[invalid], \"DAILY_YIELD_CLEAN\"] = np.nan\n",
    "            d.loc[day_idx, \"DAILY_YIELD_CLEAN\"] = (\n",
    "                d.loc[day_idx, \"DAILY_YIELD_CLEAN\"]\n",
    "                .interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "            )\n",
    "\n",
    "            prev_val = d.at[day_idx[0], \"DAILY_YIELD_CLEAN\"]\n",
    "            for t in day_idx[1:]:\n",
    "                cur = d.at[t, \"DAILY_YIELD_CLEAN\"]\n",
    "                if pd.isna(cur) or cur < prev_val:\n",
    "                    d.at[t, \"DAILY_YIELD_CLEAN\"] = prev_val\n",
    "                else:\n",
    "                    prev_val = cur\n",
    "\n",
    "            d.loc[night_mask, \"DAILY_YIELD_CLEAN\"] = 0.0\n",
    "            d.loc[evening_mask, \"DAILY_YIELD_CLEAN\"] = val_end\n",
    "\n",
    "        cleaned[sk] = d\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29824e54",
   "metadata": {},
   "source": [
    "### Clean TOTAL_YIELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ca2daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_total_yield_dict(daily_dict):\n",
    "    \"\"\"\n",
    "    Clean TOTAL_YIELD into TOTAL_YIELD_CLEAN using increments in DAILY_YIELD_CLEAN.\n",
    "    Returns dict with TOTAL_YIELD_CLEAN added, and trimmed columns + OPERATING_CONDITION_CLEAN.\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    for sk, df_in in daily_dict.items():\n",
    "        d = df_in.copy()\n",
    "        d[\"TOTAL_YIELD_CLEAN\"] = d[\"TOTAL_YIELD\"].copy()\n",
    "        timestamps = d.index\n",
    "\n",
    "        for i in range(1, len(timestamps)):\n",
    "            t_prev = timestamps[i - 1]\n",
    "            t_curr = timestamps[i]\n",
    "\n",
    "            TY_prev = d.at[t_prev, \"TOTAL_YIELD_CLEAN\"]\n",
    "            TY_now  = d.at[t_curr, \"TOTAL_YIELD\"]\n",
    "            DY_prev = d.at[t_prev, \"DAILY_YIELD_CLEAN\"]\n",
    "            DY_now  = d.at[t_curr, \"DAILY_YIELD_CLEAN\"]\n",
    "\n",
    "            is_new_day = t_curr.date() != t_prev.date()\n",
    "            if is_new_day:\n",
    "                d.at[t_curr, \"TOTAL_YIELD_CLEAN\"] = TY_prev\n",
    "                continue\n",
    "\n",
    "            delta_dy = DY_now - DY_prev\n",
    "            TY_expected = TY_prev + delta_dy\n",
    "\n",
    "            if TY_now < TY_prev:\n",
    "                d.at[t_curr, \"TOTAL_YIELD_CLEAN\"] = TY_expected\n",
    "            else:\n",
    "                d.at[t_curr, \"TOTAL_YIELD_CLEAN\"] = TY_now\n",
    "\n",
    "        cols_keep = [\n",
    "            \"PLANT_ID\", \"SOURCE_KEY\",\n",
    "            \"AC_CLEAN\", \"DC_CLEAN\",\n",
    "            \"DAILY_YIELD_CLEAN\", \"TOTAL_YIELD_CLEAN\",\n",
    "            \"AMBIENT_TEMPERATURE\", \"MODULE_TEMPERATURE\",\n",
    "            \"IRRADIATION_CLEAN\", \"NUM_OPT\", \"NUM_SUBOPT\"\n",
    "        ]\n",
    "        cols_keep = [c for c in cols_keep if c in d.columns]\n",
    "        d = d[cols_keep]\n",
    "\n",
    "        d[\"OPERATING_CONDITION_CLEAN\"] = np.where(\n",
    "            d[\"NUM_OPT\"] > d[\"NUM_SUBOPT\"], \"Optimal\", \"Suboptimal\"\n",
    "        )\n",
    "        d = d.drop(columns=[\"NUM_OPT\", \"NUM_SUBOPT\"])\n",
    "\n",
    "        cleaned[sk] = d\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80650a76",
   "metadata": {},
   "source": [
    "### Outlier Removal Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47ab60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_ps_dict(df_ps_dict):\n",
    "    \"\"\"\n",
    "    Apply regression_outlier_detection_graph to each inverter df.\n",
    "    \"\"\"\n",
    "    out_dict = {}\n",
    "    for sk, df_in in df_ps_dict.items():\n",
    "        out_dict[sk] = regression_outlier_detection_graph(\n",
    "            df_in, x_col=\"IRRADIATION_CLEAN\", y_col=\"AC_CLEAN\",\n",
    "            z_thresh=3, plot=False\n",
    "        )\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0e4fa",
   "metadata": {},
   "source": [
    "# 5. Machine Learning Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7a94f",
   "metadata": {},
   "source": [
    "### Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95a24179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label(df_all):\n",
    "    \"\"\"\n",
    "    Label: Optimal -> 0, Suboptimal -> 1\n",
    "    \"\"\"\n",
    "    return (df_all[\"OPERATING_CONDITION_CLEAN\"].str.lower() == \"suboptimal\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ba56d",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "417f678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df_all):\n",
    "    \"\"\"\n",
    "    Sort by DATE_TIME per SOURCE_KEY and add AC/IRRA, DC/IRRA.\n",
    "    \"\"\"\n",
    "    df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n",
    "        lambda g: g.sort_values(\"DATE_TIME\")\n",
    "    )\n",
    "    df_feat[\"DC/IRRA\"] = df_feat[\"DC_CLEAN\"] / (df_feat[\"IRRADIATION_CLEAN\"] + 1e-3)\n",
    "    df_feat[\"AC/IRRA\"] = df_feat[\"AC_CLEAN\"] / (df_feat[\"IRRADIATION_CLEAN\"] + 1e-3)\n",
    "    return df_feat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248cf1ea",
   "metadata": {},
   "source": [
    "### Combine All Inverter Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9037f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_all_from_df_ps(df_ps_dict):\n",
    "    \"\"\"\n",
    "    Combine all inverter dfs into one dataframe.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for sk, df_inv in df_ps_dict.items():\n",
    "        d = df_inv.copy()\n",
    "        d = d.reset_index()  # bring DATE_TIME back as a column\n",
    "        parts.append(d)\n",
    "\n",
    "    df_all = pd.concat(parts, ignore_index=True).drop_duplicates()\n",
    "    df_all[\"DATE_TIME\"] = pd.to_datetime(df_all[\"DATE_TIME\"])\n",
    "\n",
    "    mask = (~df_all[\"OPERATING_CONDITION_CLEAN\"].isna()) & (~df_all[\"IRRADIATION_CLEAN\"].isna())\n",
    "    df_all = df_all[mask]\n",
    "\n",
    "    counts = df_all[\"OPERATING_CONDITION_CLEAN\"].value_counts()\n",
    "    print(\"\\n=== Operating Condition Counts ===\")\n",
    "    print(f\"Number of Optimal (0):     {counts.get('Optimal', 0)}\")\n",
    "    print(f\"Number of Suboptimal (1):  {counts.get('Suboptimal', 0)}\")\n",
    "\n",
    "    return df_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d48c7a",
   "metadata": {},
   "source": [
    "### Time-Based Splitting (Prevents leakage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0393cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split(df_feat, y, test_days=10, val_days=3):\n",
    "    \"\"\"\n",
    "    Chronological split into train/val/test.\n",
    "    \"\"\"\n",
    "    last_time = df_feat[\"DATE_TIME\"].max()\n",
    "    test_start = last_time - pd.Timedelta(days=test_days)\n",
    "    val_start  = test_start - pd.Timedelta(days=val_days)\n",
    "\n",
    "    mask_test = df_feat[\"DATE_TIME\"] >= test_start\n",
    "    mask_val  = (df_feat[\"DATE_TIME\"] >= val_start) & (~mask_test)\n",
    "    mask_train = df_feat[\"DATE_TIME\"] < val_start\n",
    "\n",
    "    X_tr = df_feat[mask_train]\n",
    "    X_val = df_feat[mask_val]\n",
    "    X_te = df_feat[mask_test]\n",
    "\n",
    "    y_tr = y[mask_train]\n",
    "    y_val = y[mask_val]\n",
    "    y_te = y[mask_test]\n",
    "\n",
    "    return X_tr, X_val, X_te, y_tr, y_val, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024712a",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline (StandardScaler on numeric columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6551fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(df_feat, drop_col):\n",
    "    \"\"\"\n",
    "    StandardScaler on numeric columns not in drop_col.\n",
    "    \"\"\"\n",
    "    num_cols = [\n",
    "        c for c in df_feat.columns\n",
    "        if c not in drop_col and df_feat[c].dtype.kind in \"fcui\"\n",
    "    ]\n",
    "    pre = ColumnTransformer(\n",
    "        [(\"num\", Pipeline([(\"scaler\", StandardScaler())]), num_cols)]\n",
    "    )\n",
    "    return pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad6139",
   "metadata": {},
   "source": [
    "### Select Threshold that Maximises F1 for Suboptimal Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9a5dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Suboptimal_f1_threshold(y_true, scores_suboptimal):\n",
    "    \"\"\"\n",
    "    Pick threshold that maximises F1 for the Suboptimal (1) class.\n",
    "    \"\"\"\n",
    "    p, r, thr = precision_recall_curve(y_true, scores_suboptimal)\n",
    "    if len(thr) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    f1 = 2 * p[1:] * r[1:] / (p[1:] + r[1:] + 1e-12)\n",
    "    best_ix = np.nanargmax(f1)\n",
    "    return float(thr[best_ix])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64dc81",
   "metadata": {},
   "source": [
    "### Evaluation: Confusion Matrix, Classification Report, PR-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fe25d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Suboptimal_evaluate(name, y_true, scores_suboptimal, thr, tag):\n",
    "    \"\"\"\n",
    "    Print confusion matrix + classification report + PR-AUC focused on suboptimal.\n",
    "    \"\"\"\n",
    "    preds = (scores_suboptimal >= thr).astype(int)\n",
    "    ap = average_precision_score(y_true, scores_suboptimal)\n",
    "    print(f\"\\n==== {name} | {tag} ====\")\n",
    "    print(f\"Suboptimal focused Threshold: {thr:.4f} | PR-AUC: {ap:.4f}\")\n",
    "    print(classification_report(y_true, preds, digits=3))\n",
    "    print(\"Suboptimal focused Confusion Matrix:\\n\", confusion_matrix(y_true, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead0480",
   "metadata": {},
   "source": [
    "### Compute F1 Score Using a Custom Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c063a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_threshold_scorer(model, X, y_true, thr):\n",
    "    \"\"\"\n",
    "    Compute F1 (Suboptimal=1) for a given model and threshold.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scores = model.predict_proba(X)[:, 1]\n",
    "    except Exception:\n",
    "        scores = model.decision_function(X)\n",
    "    preds = (scores > thr).astype(int)\n",
    "    return f1_score(y_true, preds, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8d5d3",
   "metadata": {},
   "source": [
    "### 1-D ALE Plots for Model Interpretability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "add632c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ale_1d(model, X, feature, bins=20, save_path=None):\n",
    "    # Run ALE\n",
    "    ale(X=X, model=model, feature=[feature], include_CI=False, grid_size=bins)\n",
    "\n",
    "    # Sanitize filename\n",
    "    safe_feature = str(feature)\n",
    "    for bad in [\"/\", \"\\\\\", \":\", \"*\", \"?\", \"\\\"\", \"<\", \">\", \"|\"]:\n",
    "        safe_feature = safe_feature.replace(bad, \"_\")\n",
    "\n",
    "    plt.title(f\"ALE for {feature}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        file = os.path.join(save_path, f\"ALE_{safe_feature}.png\")\n",
    "        plt.savefig(file)\n",
    "\n",
    "    plt.show()  # prevents display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60794f",
   "metadata": {},
   "source": [
    "### Drop-Column Importance (Re-trains SVM per feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1281c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column_importance(df_feat, baseline_f1, drop_col,\n",
    "                           X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "    \"\"\"\n",
    "    Drop-column importance using LinearSVC: importance = baseline_f1 - dropped_f1.\n",
    "    \"\"\"\n",
    "    importances = {}\n",
    "    base_drop_cols = set(drop_col)\n",
    "\n",
    "    for col in X_tr.columns:\n",
    "        if col in base_drop_cols:\n",
    "            continue\n",
    "\n",
    "        X_tr_d = X_tr.drop(columns=[col])\n",
    "        X_val_d = X_val.drop(columns=[col])\n",
    "        X_te_d = X_te.drop(columns=[col])\n",
    "\n",
    "        df_feat_d = df_feat.drop(columns=[col])\n",
    "        pre_d = make_preprocessor(df_feat_d, drop_col)\n",
    "\n",
    "        svm_d = Pipeline([\n",
    "            (\"pre\", pre_d),\n",
    "            (\"clf\", LinearSVC(class_weight=\"balanced\", max_iter=5000))\n",
    "        ])\n",
    "        svm_d.fit(X_tr_d, y_tr)\n",
    "\n",
    "        thr_d = Suboptimal_f1_threshold(y_val, svm_d.decision_function(X_val_d))\n",
    "        dropped_f1 = f1_threshold_scorer(svm_d, X_te_d, y_te, thr_d)\n",
    "\n",
    "        importances[col] = baseline_f1 - dropped_f1\n",
    "\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50599e",
   "metadata": {},
   "source": [
    "# 6. End-to-End Classification Pipeline for a Plant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c21d0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_on_df_ps(df_ps_dict, test_days=10, val_days=3, drop_col=None):\n",
    "    \"\"\"\n",
    "    Full pipeline + SAVE plots + SHOW plots + unique filenames per run.\n",
    "    ALE is computed on TRAINING data (correct theoretical usage).\n",
    "    \"\"\"\n",
    "\n",
    "    run_count = 0\n",
    "\n",
    "    # global run_count\n",
    "    # run_count += 1   # increment unique run ID\n",
    "\n",
    "    # ================================================================\n",
    "    # FOLDER SETUP\n",
    "    # ================================================================\n",
    "\n",
    "############################################################################################################################################\n",
    "    \n",
    "    # Change here \n",
    "\n",
    "    base_path = r\"C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\"\n",
    "\n",
    "######################################################################################################################################################################\n",
    "    \n",
    "    folder_main = os.path.join(base_path, \"03 ALE SVM Decision\")\n",
    "    folder_plots = os.path.join(folder_main, \"Plots\")\n",
    "    folder_ale = os.path.join(folder_plots, \"ALE\")\n",
    "    folder_svm = os.path.join(folder_plots, \"SVM\")\n",
    "\n",
    "    ensure_dir(folder_main)\n",
    "    ensure_dir(folder_plots)\n",
    "    ensure_dir(folder_ale)\n",
    "    ensure_dir(folder_svm)\n",
    "\n",
    "    # ================================================================\n",
    "    # DATA PREPARATION\n",
    "    # ================================================================\n",
    "    if drop_col is None:\n",
    "        drop_col = [\"OPERATING_CONDITION_CLEAN\", \"DATE_TIME\", \"PLANT_ID\", \"SOURCE_KEY\"]\n",
    "\n",
    "    df_all = assemble_all_from_df_ps(df_ps_dict)\n",
    "    y = make_label(df_all)\n",
    "    df_feat = engineer_features(df_all)\n",
    "\n",
    "    # train/val/test split\n",
    "    X_tr, X_val, X_te, y_tr, y_val, y_te = time_split(df_feat, y, test_days, val_days)\n",
    "\n",
    "    X_tr_model = X_tr.drop(columns=drop_col)\n",
    "    X_val_model = X_val.drop(columns=drop_col)\n",
    "    X_te_model = X_te.drop(columns=drop_col)\n",
    "\n",
    "    pre = make_preprocessor(df_feat, drop_col)\n",
    "\n",
    "    class_weights_arr = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=y_tr)\n",
    "    class_weights = {0: class_weights_arr[0], 1: class_weights_arr[1]}\n",
    "\n",
    "    # ================================================================\n",
    "    # MODELS\n",
    "    # ================================================================\n",
    "    print(\"\\n=== LogReg with scaling ===\")\n",
    "    lr = Pipeline([(\"pre\", pre),(\"clf\", LogisticRegression(max_iter=5000, class_weight=class_weights))])\n",
    "    lr.fit(X_tr_model, y_tr)\n",
    "    print(\"\\n=== LogReg without scaling ===\")\n",
    "    lr_ns = LogisticRegression(max_iter=5000, class_weight=class_weights)\n",
    "    lr_ns.fit(X_tr_model, y_tr)\n",
    "    print(\"\\n=== LinearSVC with scaling ===\")\n",
    "    svm = Pipeline([(\"pre\", pre),(\"clf\", LinearSVC(class_weight=\"balanced\", max_iter=5000))])\n",
    "    svm.fit(X_tr_model, y_tr)\n",
    "    print(\"\\n=== LinearSVC without scaling ===\")\n",
    "    svm_ns = LinearSVC(class_weight=\"balanced\", max_iter=5000)\n",
    "    svm_ns.fit(X_tr_model, y_tr)\n",
    "\n",
    "    # ================================================================\n",
    "    # THRESHOLDS\n",
    "    # ================================================================\n",
    "    thr_lr = Suboptimal_f1_threshold(y_val, lr.predict_proba(X_val_model)[:,1])\n",
    "    thr_lr_ns = Suboptimal_f1_threshold(y_val, lr_ns.predict_proba(X_val_model)[:,1])\n",
    "    thr_svm = Suboptimal_f1_threshold(y_val, svm.decision_function(X_val_model))\n",
    "    thr_svm_ns = Suboptimal_f1_threshold(y_val, svm_ns.decision_function(X_val_model))\n",
    "\n",
    "    # ================================================================\n",
    "    # ALE PLOTS — SAVE + SHOW (on X_tr_model)\n",
    "    # ================================================================\n",
    "    print(\"\\n=== Saving ALE plots (train set, correct) ===\")\n",
    "    for feat in tqdm(X_tr_model.columns):\n",
    "        plot_ale_1d(\n",
    "            svm,                      # model\n",
    "            X_tr_model,               # ALE should use TRAINING DATA\n",
    "            feat,\n",
    "            save_path=folder_ale      # SAVE ONLY (but we also show)\n",
    "        )\n",
    "        plt.show()  # show the plot after saving\n",
    "\n",
    "    # ================================================================\n",
    "    # DROP-COLUMN IMPORTANCE\n",
    "    # ================================================================\n",
    "    baseline_f1 = f1_threshold_scorer(svm, X_te_model, y_te, thr_svm)\n",
    "\n",
    "    svm_importance = drop_column_importance(\n",
    "        df_feat, baseline_f1, drop_col,\n",
    "        X_tr_model, y_tr, X_val_model, y_val, X_te_model, y_te\n",
    "    )\n",
    "\n",
    "    # ================================================================\n",
    "    # SVM DECISION HISTOGRAM — UNIQUE FILENAME\n",
    "    # ================================================================\n",
    "    safe_name = f\"Run_{run_count}\"\n",
    "    hist_file = os.path.join(folder_svm, f\"SVM_Decision_Histogram_{safe_name}.png\")\n",
    "\n",
    "    scores_te = svm.decision_function(X_te_model)\n",
    "\n",
    "    plt.hist(scores_te[y_te == 0], bins=50, alpha=0.6, label=\"Optimal\")\n",
    "    plt.hist(scores_te[y_te == 1], bins=50, alpha=0.6, label=\"Suboptimal\")\n",
    "    plt.axvline(thr_svm, linestyle=\"--\", label=\"boundary\")\n",
    "    plt.xlabel(\"SVM decision function\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.savefig(hist_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved SVM histogram → {hist_file}\")\n",
    "\n",
    "    # ================================================================\n",
    "    # SAVE RESULTS (PKL) — UNIQUE FILE NAME\n",
    "    # ================================================================\n",
    "    pkl_file = os.path.join(folder_main, f\"results_Run_{run_count}.pkl\")\n",
    "\n",
    "    results_dict = {\n",
    "        \"LogReg_scaled\": lr,\n",
    "        \"LogReg_no_scaling\": lr_ns,\n",
    "        \"SVM_scaled\": svm,\n",
    "        \"SVM_no_scaling\": svm_ns,\n",
    "        \"thresholds\": {\n",
    "            \"lr\": thr_lr,\n",
    "            \"lr_ns\": thr_lr_ns,\n",
    "            \"svm\": thr_svm,\n",
    "            \"svm_ns\": thr_svm_ns\n",
    "        },\n",
    "        \"drop_column_importance\": svm_importance,\n",
    "        \"baseline_f1\": baseline_f1,\n",
    "        \"features\": list(X_te_model.columns),\n",
    "    }\n",
    "\n",
    "    with open(pkl_file, \"wb\") as f:\n",
    "        pickle.dump(results_dict, f)\n",
    "\n",
    "    print(f\"Saved results to → {pkl_file}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d593ab7",
   "metadata": {},
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe7a0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0. PATHS\n",
    "# ============================================================\n",
    "\n",
    "############################################################################################################################################\n",
    "# Change here \n",
    "\n",
    "folder = r\"C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\In\"\n",
    "\n",
    "############################################################################################################################################\n",
    "\n",
    "gen_path_1     = os.path.join(folder, \"Plant_1_Generation_Data_updated.csv\")   # Plant 1 generation\n",
    "weather_path_1 = os.path.join(folder, \"Plant_1_Weather_Sensor_Data.csv\")       # Plant 1 weather\n",
    "\n",
    "gen_path_2     = os.path.join(folder, \"Plant_2_Generation_Data.csv\")           # Plant 2 generation\n",
    "weather_path_2 = os.path.join(folder, \"Plant_2_Weather_Sensor_Data.csv\")       # Plant 2 weather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da144d3",
   "metadata": {},
   "source": [
    "### Main Pipeline: Plant 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79ca2c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PLANT 1: LOADING DATA ===\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. MAIN PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "# ------------------ Plant 1 ------------------\n",
    "\n",
    "print(\"\\n=== PLANT 1: LOADING DATA ===\")\n",
    "df_p1_gen_raw = pd.read_csv(gen_path_1, parse_dates=[\"DATE_TIME\"])\n",
    "df_p1_weather_raw = pd.read_csv(weather_path_1, parse_dates=[\"DATE_TIME\"])\n",
    "\n",
    "# Drop rows with missing Operating_Condition, drop PLANT_ID and 'day' as in original\n",
    "df_p1_gen = df_p1_gen_raw.dropna().copy()\n",
    "for col_drop in [\"PLANT_ID\", \"day\"]:\n",
    "    if col_drop in df_p1_gen.columns:\n",
    "        df_p1_gen = df_p1_gen.drop(columns=[col_drop])\n",
    "df_p1_gen.set_index(\"DATE_TIME\", inplace=True)\n",
    "\n",
    "# Aggregate by inverter\n",
    "df_p1_gen.reset_index(inplace=True)\n",
    "agg_inv_p1 = aggregate_inverters(df_p1_gen)\n",
    "\n",
    "# Clean weather\n",
    "df_p1_weather = clean_weather(df_p1_weather_raw)\n",
    "\n",
    "# Join inverter + weather\n",
    "wea_inv_p1 = merge_inverter_weather(agg_inv_p1, df_p1_weather)\n",
    "\n",
    "# Clean AC/DC, DAILY_YIELD, TOTAL_YIELD\n",
    "p1_step1 = clean_ac_dc_dict(wea_inv_p1)\n",
    "p1_step2 = clean_daily_yield_dict(p1_step1)\n",
    "df_ps1 = clean_total_yield_dict(p1_step2)\n",
    "\n",
    "# Outlier removal\n",
    "df_ps1_outlier = remove_outliers_ps_dict(df_ps1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cd394",
   "metadata": {},
   "source": [
    "### Main Pipeline: Plant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3017e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PLANT 2: LOADING DATA ===\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Plant 2 ------------------\n",
    "\n",
    "print(\"\\n=== PLANT 2: LOADING DATA ===\")\n",
    "df_p2_gen_raw = pd.read_csv(gen_path_2, parse_dates=[\"DATE_TIME\"])\n",
    "df_p2_weather_raw = pd.read_csv(weather_path_2, parse_dates=[\"DATE_TIME\"])\n",
    "\n",
    "# Drop PLANT_ID from generation (as in original)\n",
    "if \"PLANT_ID\" in df_p2_gen_raw.columns:\n",
    "    df_p2_gen = df_p2_gen_raw.drop(columns=[\"PLANT_ID\"]).copy()\n",
    "else:\n",
    "    df_p2_gen = df_p2_gen_raw.copy()\n",
    "\n",
    "df_p2_gen.set_index(\"DATE_TIME\", inplace=True)\n",
    "df_p2_gen.reset_index(inplace=True)\n",
    "\n",
    "agg_inv_p2 = aggregate_inverters(df_p2_gen)\n",
    "df_p2_weather = clean_weather(df_p2_weather_raw)\n",
    "wea_inv_p2 = merge_inverter_weather(agg_inv_p2, df_p2_weather)\n",
    "\n",
    "p2_step1 = clean_ac_dc_dict(wea_inv_p2)\n",
    "p2_step2 = clean_daily_yield_dict(p2_step1)\n",
    "df_ps2 = clean_total_yield_dict(p2_step2)\n",
    "\n",
    "df_ps2_outlier = remove_outliers_ps_dict(df_ps2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044deaa8",
   "metadata": {},
   "source": [
    "### Experiments: With/Without Outliers, Before/After Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ab950fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================\n",
      "PLANT 1: SVM BEFORE FEATURE SELECTION (WITH OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     7656\n",
      "Number of Suboptimal (1):  38024\n",
      "\n",
      "=== LogReg with scaling ===\n",
      "\n",
      "=== LogReg without scaling ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 11%|█         | 1/9 [00:13<01:45, 13.17s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 22%|██▏       | 2/9 [00:25<01:28, 12.69s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 33%|███▎      | 3/9 [00:41<01:25, 14.29s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 44%|████▍     | 4/9 [00:53<01:06, 13.39s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 56%|█████▌    | 5/9 [01:03<00:48, 12.02s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 67%|██████▋   | 6/9 [01:14<00:35, 11.88s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 78%|███████▊  | 7/9 [01:25<00:22, 11.29s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 89%|████████▉ | 8/9 [01:36<00:11, 11.22s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 9/9 [01:50<00:00, 12.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "PLANT 1: AFTER FEATURE SELECTION (WITH OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     7656\n",
      "Number of Suboptimal (1):  38024\n",
      "\n",
      "=== LogReg with scaling ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogReg without scaling ===\n",
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 33%|███▎      | 1/3 [00:17<00:34, 17.38s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 67%|██████▋   | 2/3 [00:30<00:14, 14.73s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 3/3 [00:40<00:00, 13.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "PLANT 1: SVM BEFORE FEATURE SELECTION (WITHOUT OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     6817\n",
      "Number of Suboptimal (1):  37737\n",
      "\n",
      "=== LogReg with scaling ===\n",
      "\n",
      "=== LogReg without scaling ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 11%|█         | 1/9 [00:13<01:46, 13.28s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 22%|██▏       | 2/9 [00:27<01:36, 13.76s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 33%|███▎      | 3/9 [00:41<01:22, 13.73s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 44%|████▍     | 4/9 [00:51<01:01, 12.28s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 56%|█████▌    | 5/9 [00:59<00:43, 10.89s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 67%|██████▋   | 6/9 [01:08<00:30, 10.06s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 78%|███████▊  | 7/9 [01:15<00:18,  9.17s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 89%|████████▉ | 8/9 [01:25<00:09,  9.42s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 9/9 [01:35<00:00, 10.60s/it]\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "PLANT 1: AFTER FEATURE SELECTION (WITHOUT OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     6817\n",
      "Number of Suboptimal (1):  37737\n",
      "\n",
      "=== LogReg with scaling ===\n",
      "\n",
      "=== LogReg without scaling ===\n",
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 33%|███▎      | 1/3 [00:12<00:25, 12.62s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 67%|██████▋   | 2/3 [00:20<00:09,  9.94s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PyALE\\_src\\ALE_1D.py:326: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(8, 4))\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 3/3 [00:28<00:00,  9.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "PLANT 2: Before FEATURE SELECTION MODEL (WITH OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     7414\n",
      "Number of Suboptimal (1):  60284\n",
      "\n",
      "=== LogReg with scaling ===\n",
      "\n",
      "=== LogReg without scaling ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PyALE\\_src\\ALE_1D.py:326: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(8, 4))\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 11%|█         | 1/9 [00:12<01:43, 12.88s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 22%|██▏       | 2/9 [00:26<01:32, 13.18s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 33%|███▎      | 3/9 [00:43<01:28, 14.82s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 44%|████▍     | 4/9 [00:57<01:13, 14.65s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 56%|█████▌    | 5/9 [01:10<00:55, 13.96s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 67%|██████▋   | 6/9 [01:22<00:39, 13.33s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 78%|███████▊  | 7/9 [01:32<00:24, 12.17s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 89%|████████▉ | 8/9 [01:45<00:12, 12.49s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 9/9 [01:57<00:00, 13.06s/it]\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "PLANT 2: After FEATURE SELECTION MODEL (WITH OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     7414\n",
      "Number of Suboptimal (1):  60284\n",
      "\n",
      "=== LogReg with scaling ===\n",
      "\n",
      "=== LogReg without scaling ===\n",
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 33%|███▎      | 1/3 [00:13<00:27, 13.82s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 67%|██████▋   | 2/3 [00:23<00:11, 11.43s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 3/3 [00:35<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "PLANT 2: SVM BEFORE FEATURE SELECTION (WITHOUT OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     6383\n",
      "Number of Suboptimal (1):  59435\n",
      "\n",
      "=== LogReg with scaling ===\n",
      "\n",
      "=== LogReg without scaling ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 11%|█         | 1/9 [00:12<01:36, 12.04s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 22%|██▏       | 2/9 [00:23<01:23, 11.97s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 33%|███▎      | 3/9 [00:39<01:21, 13.54s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 44%|████▍     | 4/9 [00:52<01:07, 13.44s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 56%|█████▌    | 5/9 [01:04<00:51, 12.76s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 67%|██████▋   | 6/9 [01:15<00:36, 12.33s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 78%|███████▊  | 7/9 [01:26<00:23, 11.74s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 89%|████████▉ | 8/9 [01:38<00:12, 12.05s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 9/9 [01:51<00:00, 12.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "PLANT 2: AFTER FEATURE SELECTION (WITHOUT OUTLIERS)\n",
      "==============================\n",
      "\n",
      "=== Operating Condition Counts ===\n",
      "Number of Optimal (0):     6383\n",
      "Number of Suboptimal (1):  59435\n",
      "\n",
      "=== LogReg with scaling ===\n",
      "\n",
      "=== LogReg without scaling ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3924378580.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_all.groupby(\"SOURCE_KEY\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearSVC with scaling ===\n",
      "\n",
      "=== LinearSVC without scaling ===\n",
      "\n",
      "=== Saving ALE plots (train set, correct) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 12%|█▎        | 1/8 [00:13<01:33, 13.42s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 25%|██▌       | 2/8 [00:26<01:19, 13.27s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 38%|███▊      | 3/8 [00:42<01:11, 14.27s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 50%|█████     | 4/8 [00:53<00:52, 13.10s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 62%|██████▎   | 5/8 [01:05<00:38, 12.77s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 75%|███████▌  | 6/8 [01:14<00:23, 11.61s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      " 88%|████████▊ | 7/8 [01:26<00:11, 11.52s/it]PyALE._ALE_generic:INFO: Continuous feature detected.\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\599838501.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # prevents display\n",
      "C:\\Users\\B.KING\\AppData\\Local\\Temp\\ipykernel_66896\\3027487920.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()  # show the plot after saving\n",
      "100%|██████████| 8/8 [01:37<00:00, 12.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM histogram → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\Plots\\SVM\\SVM_Decision_Histogram_Run_0.png\n",
      "Saved results to → C:\\Users\\B.KING\\OneDrive - Imperial College London\\CIVE70111 Machine Learning\\CouseWork\\Group-11\\data\\03 ALE SVM Decision\\results_Run_0.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. EXPERIMENTS (as in your original script)\n",
    "# ============================================================\n",
    "\n",
    "drop_base = [\"OPERATING_CONDITION_CLEAN\", \"DATE_TIME\", \"PLANT_ID\", \"SOURCE_KEY\"]\n",
    "\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 1: SVM BEFORE FEATURE SELECTION (WITH OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps1, drop_col=drop_base)\n",
    "\n",
    "drop1 = drop_base + ['AC/IRRA', 'DC/IRRA', 'MODULE_TEMPERATURE','TOTAL_YIELD_CLEAN', 'DC_CLEAN', 'AC_CLEAN']\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 1: AFTER FEATURE SELECTION (WITH OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps1, drop_col=drop1)\n",
    "\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 1: SVM BEFORE FEATURE SELECTION (WITHOUT OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps1_outlier, drop_col=drop_base)\n",
    "\n",
    "drop2 = drop_base + ['AC/IRRA', 'DC/IRRA', 'MODULE_TEMPERATURE','TOTAL_YIELD_CLEAN', 'DC_CLEAN', 'AC_CLEAN']\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 1: AFTER FEATURE SELECTION (WITHOUT OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps1_outlier, drop_col=drop2)\n",
    "\n",
    "# Comment from your notes:\n",
    "# The removed outliers are actually those optimal condition correctly predicted by the model,\n",
    "# hence removing outliers worsens model performance.\n",
    "\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 2: Before FEATURE SELECTION MODEL (WITH OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps2, drop_col=drop_base)\n",
    "\n",
    "drop3 = drop_base + ['DAILY_YIELD_CLEAN', 'AMBIENT_TEMPERATURE','MODULE_TEMPERATURE', 'AC_CLEAN','TOTAL_YIELD_CLEAN','DC/IRRA']\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 2: After FEATURE SELECTION MODEL (WITH OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps2, drop_col=drop3)\n",
    "\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 2: SVM BEFORE FEATURE SELECTION (WITHOUT OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps2_outlier, drop_col=drop_base)\n",
    "\n",
    "drop4 = drop_base + ['TOTAL_YIELD_CLEAN']\n",
    "print(\"\\n\\n==============================\")\n",
    "print(\"PLANT 2: AFTER FEATURE SELECTION (WITHOUT OUTLIERS)\")\n",
    "print(\"==============================\")\n",
    "run_classification_on_df_ps(df_ps2_outlier, drop_col=drop4)\n",
    "# Comment from your notes:\n",
    "# Does not perform better after feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c2dce",
   "metadata": {},
   "source": [
    "### Summary\n",
    "All models have poorer performance when trained without feature scaling because it prevents large features (such as AC and DC) from dominating the loss function while small feature (such as irradiation) is ignored.\n",
    "\n",
    "Feature selection was performed using the drop-column method. Each feature was removed in turn, and the model was retrained to measure the change in performance. A positive importance value indicates that the feature contributes to model performance. A value of zero suggests the feature is redundant, and a negative value indicates the feature reduces model performance. Features were removed until all remaining features had positive importance values.\n",
    "\n",
    "\n",
    "For Plant 1, the retained features are daily yield, ambient temperature, and irradiation.\n",
    "\n",
    "\n",
    "For Plant 2, the retained features are DC power, irradiation, and the ratio of AC power to irradiation (AC/IRRA).\n",
    "\n",
    "The effect of each feature on model predictions was calculated using accumulated local effects (ALE), a method that remains reliable even when features are correlated. For the LinearSVC model, more negative prediction values correspond to a higher probability of the inverter being in an optimal state. More positive values indicate a higher probability of being suboptimal. For Plant 1, the ALE plots show that increases in daily yield and irradiation lead to more negative prediction values, indicating a higher likelihood of optimal performance. In contrast, higher ambient temperatures raise the prediction value, which signals a greater probability of suboptimal performance. In summary, maintaining optimal operation in Plant 1 requires lower ambient temperatures and sufficient irradiation so that both irradiation and daily yield can increase. For Plant 2, higher irradiation and higher DC output both move the inverter toward an optimal state. An increase in the AC-to-irradiation ratio, however, shifts the inverter toward suboptimal performance. To support optimal operation in Plant 2, locating the plant in an area with strong and consistent sunlight is beneficial.\n",
    "\n",
    "Data Quality Issues:\n",
    "\n",
    "\n",
    "A key limitation was the uneven distribution between optimal and suboptimal operating states. Optimal events are relatively rare, leading the model to bias predictions toward the majority class. Although threshold tuning and class weighting help, the imbalance fundamentally limits the model’s ability to learn subtle patterns associated with rare operational faults. \n",
    "\n",
    "\n",
    "Model Assumptions and Limitations:\n",
    "\n",
    "\n",
    "LinearSVC assumes that the two classes can be separated by a linear decision boundary in feature space. In reality, inverter performance is influenced by complex relationships such as: non-linear efficiency curves,\n",
    "interaction between temperature and irradiation, operational hysteresis effects.These interactions are difficult for a linear model to capture, limiting predictive accuracy.\n",
    "\n",
    "\n",
    "Challenges:\n",
    "\n",
    "\n",
    "It is difficult to identity the outliers in the data that affected the classification model performance, eventhough outliers are removed based on linear regression model. \n",
    "\n",
    "\n",
    "\n",
    "Data Collection and Quality Improvements:\n",
    "\n",
    "\n",
    "Increase representative coverage of minority class. my model’s difficulty in detecting optimal or suboptimal states (depending on imbalance structure) often comes from limited examples of optimal class, which can be improved by: collecting more data for optimal operating conditions .\n",
    "\n",
    "\n",
    "Alternative Modelling Approaches to Improve Prediction:\n",
    "\n",
    "\n",
    "Even if LinearSVC performs reasonably, consider alternative models that can capture non-linearities or provide complementary insights. Non-linear models such as RBF-SVM, XGBoost and Logistic Regression with engineered polynomial features, are able to capture non-linear feature interactions\n",
    "\n",
    "\n",
    "Real world application:\n",
    "\n",
    "\n",
    "One application will be applying the results of the model to find out the factors causing the inverters to be suboptimal so that corresponding measures can be implemented to prevent inverters from being suboptimal. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
